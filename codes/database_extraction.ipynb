{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addb617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from constants import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from indexing import Indexer, IndexType\n",
    "from document_preprocessor import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9254c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430328/430328 [00:06<00:00, 61707.44it/s] \n",
      "100%|██████████| 95016/95016 [00:41<00:00, 2293.60it/s] \n"
     ]
    }
   ],
   "source": [
    "document_preprocessor = RegexTokenizer('\\\\w+')\n",
    "stopwords = set()\n",
    "with open(STOPWORD_PATH, \"r\") as f:\n",
    "    for word in f:\n",
    "        stopwords.add(word.strip())\n",
    "title_index = Indexer.create_index(IndexType.InvertedIndex, PAPER_DATA_PATH,\n",
    "                     document_preprocessor, stopwords, minimum_word_frequency=1, text_key=\"title\")\n",
    "# title_index.save(PAPER_TITLE_INDEX)\n",
    "\n",
    "abstract_index = Indexer.create_index_from_inverted_index(IndexType.InvertedIndex, PAPER_DATA_PATH,\n",
    "                     stopwords, minimum_word_frequency=50)\n",
    "# abstract_index.save(PAPER_ABSTRACT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc28b6f-f4ac-4a51-ab7d-289d81802250",
   "metadata": {},
   "outputs": [],
   "source": [
    "docid_list = []\n",
    "with open(PAPER_DATA_PATH, 'r') as f:\n",
    "    for i, line in enumerate(tqdm(f, total=TOTAL_PAPER_COUNT+2)):\n",
    "        if i == 0 or i == TOTAL_PAPER_COUNT+1:\n",
    "            continue\n",
    "        if i == 1:\n",
    "            doc = json.loads(line)\n",
    "        else:\n",
    "            doc = json.loads(line[1:])\n",
    "            if 'indexed_abstract' not in doc.keys():\n",
    "                continue\n",
    "        docid_list.append(doc['id'])\n",
    "\n",
    "with open(DOCID_LIST_PATH, 'wb') as f:\n",
    "    pickle.dump(docid_list, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5abc79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Collect doc categories\")\n",
    "docid_to_categories = {}\n",
    "docid_list = []\n",
    "with open(PAPER_DATA_PATH, 'r') as f:\n",
    "    for i, line in enumerate(tqdm(f, total=TOTAL_PAPER_COUNT+2)):\n",
    "        if i == 0 or i == TOTAL_PAPER_COUNT+1:\n",
    "            continue\n",
    "        if i == 1:\n",
    "            doc = json.loads(line)\n",
    "        else:\n",
    "            doc = json.loads(line[1:])\n",
    "            if 'indexed_abstract' not in doc.keys():\n",
    "                continue\n",
    "            \n",
    "        docid_list.append(doc['id'])\n",
    "        cat_list = []\n",
    "        if 'fos' in doc:\n",
    "            for j in doc['fos']:\n",
    "                cat_list.append(j['name'])\n",
    "        docid_to_categories[doc['id']] = cat_list\n",
    "\n",
    "category_counts = Counter()\n",
    "for cats in tqdm(docid_to_categories.values(), total=len(docid_to_categories)):\n",
    "    for c in cats:\n",
    "        category_counts[c] += 1\n",
    "recognized_categories = set(\n",
    "    [cat for cat, count in category_counts.items() if count >= CATEGORIES_COUNT_CUTOFF])\n",
    "    \n",
    "print(\"Create doc_category_info\")\n",
    "doc_category_info = {}\n",
    "for docid, cats in tqdm(docid_to_categories.items(), total=len(docid_to_categories)):\n",
    "    valid_cats = [c for c in cats if c in recognized_categories]\n",
    "    doc_category_info[docid] = valid_cats\n",
    "print(\"--- Done ---\")\n",
    "\n",
    "# with open(DOC_CATEGORY_INFO_PATH, 'wb') as f:\n",
    "#     pickle.dump(doc_category_info, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open(RECOG_CATEGORY_PATH, 'wb') as f:\n",
    "#     pickle.dump(recognized_categories, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4031d95e-d8cd-41fd-93cc-0bed4ad08ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Collect year release\")\n",
    "docid_to_yr = {}\n",
    "with open(PAPER_DATA_PATH, 'r') as f:\n",
    "    for i, line in enumerate(tqdm(f, total=TOTAL_PAPER_COUNT+2)):\n",
    "        if i == 0 or i == TOTAL_PAPER_COUNT+1:\n",
    "            continue\n",
    "        if i == 1:\n",
    "            doc = json.loads(line)\n",
    "        else:\n",
    "            doc = json.loads(line[1:])\n",
    "            \n",
    "        docid_to_yr[doc['id']] = doc['year']\n",
    "# with open(DOCID_TO_YEAR_RELEASE_PATH, 'wb') as f:\n",
    "#     pickle.dump(docid_to_yr, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b08ea0a-7ebc-473c-8177-88b5f6b718ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect citation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4894083/4894083 [03:51<00:00, 21173.84it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Collect citation\")\n",
    "docid_to_citation = {}\n",
    "with open(PAPER_DATA_PATH, 'r') as f:\n",
    "    for i, line in enumerate(tqdm(f, total=TOTAL_PAPER_COUNT+2)):\n",
    "        if i == 0 or i == TOTAL_PAPER_COUNT+1:\n",
    "            continue\n",
    "        if i == 1:\n",
    "            doc = json.loads(line)\n",
    "        else:\n",
    "            doc = json.loads(line[1:])\n",
    "        if 'n_citation' in doc:\n",
    "            docid_to_citation[doc['id']] = doc['n_citation']\n",
    "with open(DOCID_TO_CITATION_PATH, 'wb') as f:\n",
    "    pickle.dump(docid_to_citation, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b3a5eb-978f-4205-9dff-7498d79fbec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect authors data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4894083/4894083 [07:08<00:00, 11415.48it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Collect authors data\")\n",
    "\"\"\"\n",
    "author_collection = {\n",
    "    author_id : {\n",
    "        'name' : author_name,\n",
    "        'org' : author_org,\n",
    "        'docid' : {\n",
    "            doc_id : author_order\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "docid_to_authorid = {}\n",
    "authorid_to_author_name = {}\n",
    "author_collection = {}\n",
    "with open(PAPER_DATA_PATH, 'r') as f:\n",
    "    for i, line in enumerate(tqdm(f, total=TOTAL_PAPER_COUNT+2)):\n",
    "        if i == 0 or i == TOTAL_PAPER_COUNT+1:\n",
    "            continue\n",
    "        if i == 1:\n",
    "            doc = json.loads(line)\n",
    "        else:\n",
    "            doc = json.loads(line[1:])\n",
    "        \n",
    "        if 'authors' not in doc:\n",
    "            continue\n",
    "            \n",
    "        # docid_to_authorid[doc['id']] = [author['id'] for author in doc['authors']]\n",
    "        \n",
    "        for i, author in enumerate(doc['authors']):\n",
    "\n",
    "            author_collection[author['id']] = {}\n",
    "            author_collection[author['id']]['name'] = author['name']\n",
    "            \n",
    "            if 'org' not in author_collection[author['id']]:\n",
    "                author_collection[author['id']]['org'] = set()\n",
    "            if 'org' in author:\n",
    "                author_collection[author['id']]['org'].add(author['org'])\n",
    "            \n",
    "            if 'docid' not in author_collection[author['id']]:\n",
    "                author_collection[author['id']]['docid'] = {}\n",
    "            author_collection[author['id']]['docid'][doc['id']] =  i\n",
    "            \n",
    "            \n",
    "            # if author['id'] not in authorid_to_author_name:\n",
    "            #     authorid_to_author_name[author['id']] = author['name']\n",
    "\n",
    "# with open(DOCID_TO_AUTHORID_PATH, 'wb') as f:\n",
    "#     pickle.dump(docid_to_authorid, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(AUTHOR_COLLECTION_PATH, 'wb') as f:\n",
    "    pickle.dump(author_collection, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open(AUTHORID_TO_AUTHOR_NAME_PATH, 'wb') as f:\n",
    "#     pickle.dump(authorid_to_author_name, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829a65e4-5209-41a8-ac0a-ed6ba2fbd965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4344"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Collect network stats info\")\n",
    "with open(PAPER_NETWORK_METRICS_PATH, 'rb') as f:\n",
    "    network_stat_dict = pickle.load(f)\n",
    "\n",
    "docid_to_network_features = defaultdict(dict)\n",
    "for i, docid in enumerate(tqdm(network_stat_dict['node_names'])):\n",
    "    for score in ['pgr_scores', 'hub_scores', 'auth_scores', 'paris_hierarchy', 'pca_scores']:\n",
    "    # for score in ['pgr_scores', 'hub_scores', 'auth_scores', 'paris_hierarchy', 'louvain_membership', 'pca_scores']:\n",
    "        # if score == 'louvain_membership':\n",
    "        #     docid_to_network_features[docid][score] = network_stat_dict['louvain_membership'][i].toarray().tolist()[0]\n",
    "        if score in ['paris_hierarchy', 'pca_scores']:\n",
    "            docid_to_network_features[docid][score] = network_stat_dict[score][i].tolist()\n",
    "        else:\n",
    "            docid_to_network_features[docid][score] = network_stat_dict[score][i]\n",
    "            \n",
    "# with open(DOCID_TO_NETWORK_FEATURES_PATH, 'wb') as f:\n",
    "#     pickle.dump(docid_to_network_features, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db4ff4-a912-4490-8886-92af0d8b60ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect encoded doc title\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 4726090/4894083 [10:19:21<21:43, 128.88it/s] "
     ]
    }
   ],
   "source": [
    "print(\"Collect encoded doc title\")\n",
    "encoder = SentenceTransformer(BIENCODER_MODEL_NAME)\n",
    "\n",
    "encoded_title_array = []\n",
    "docid_to_rowidx = {}\n",
    "\n",
    "docid_to_title_vec = {}\n",
    "row_idx = 0\n",
    "with open(PAPER_DATA_PATH, 'r') as f:\n",
    "    for i, line in enumerate(tqdm(f, total=TOTAL_PAPER_COUNT+2)):\n",
    "        if i == 0 or i == TOTAL_PAPER_COUNT+1:\n",
    "            continue\n",
    "        if i == 1:\n",
    "            doc = json.loads(line)\n",
    "        else:\n",
    "            doc = json.loads(line[1:])\n",
    "            \n",
    "        encoded_title_array.append(encoder.encode(doc['title']))\n",
    "        docid_to_rowidx[doc['id']] = row_idx\n",
    "        row_idx += 1\n",
    "        \n",
    "with open(ENCODED_TITLE_ARRAY_PATH, 'wb') as f:\n",
    "    pickle.dump(encoded_title_array, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(DOCID_TO_TITLE_VEC_ROWIDX_PATH, 'wb') as f:\n",
    "    pickle.dump(docid_to_rowidx, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
